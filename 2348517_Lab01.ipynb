{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CbpiHEn0XVjr"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwCyw33kYQ-c",
        "outputId": "b721d8f3-14b2-48d4-f6e6-8fd0adc23f16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_data = \"I am Epsita, a student of Christ University - Central Campus, Bengaluru who is pursuing MSc in AI and ML\"\n",
        "nltk_tokens = nltk.word_tokenize(word_data)\n",
        "print (nltk_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ufLUSGX6FS",
        "outputId": "fc1f3cc0-fb75-479c-fdeb-7f7bf3b96ce2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'Epsita', ',', 'a', 'student', 'of', 'Christ', 'University', '-', 'Central', 'Campus', ',', 'Bengaluru', 'who', 'is', 'pursuing', 'MSc', 'in', 'AI', 'and', 'ML']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_data = \"I am Epsita. I am a student of Christ University - Central Campus, Bengaluru, Karnataka. I am pursuing MSc in AI and ML\"\n",
        "nltk_tokens = nltk.sent_tokenize(sentence_data)\n",
        "print (nltk_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF4o1_N5YLzu",
        "outputId": "f472ae77-d723-4406-af18-707662f59fc4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I am Epsita.', 'I am a student of Christ University - Central Campus, Bengaluru, Karnataka.', 'I am pursuing MSc in AI and ML']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "metadata": {
        "id": "ZzRHYYeAY4cQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Reset your password if you just can't remember your old one.\"\n",
        "print(\"\\nOriginal string:\")\n",
        "print(text)\n",
        "result = WordPunctTokenizer().tokenize(text)\n",
        "print(\"\\nSplit all punctuation into separate tokens:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VHgKkdVYoQn",
        "outputId": "7d3a47ea-5316-4f7b-e882-245abcd5761e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original string:\n",
            "Reset your password if you just can't remember your old one.\n",
            "\n",
            "Split all punctuation into separate tokens:\n",
            "['Reset', 'your', 'password', 'if', 'you', 'just', 'can', \"'\", 't', 'remember', 'your', 'old', 'one', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordTokenizer, TreebankWordDetokenizer"
      ],
      "metadata": {
        "id": "Ofhwddj-Y7x6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\nThanks.'''\n",
        "d = TreebankWordDetokenizer()\n",
        "t = TreebankWordTokenizer()\n",
        "toks = t.tokenize(s)\n",
        "d.detokenize(toks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TnRa7sbfZKvf",
        "outputId": "95d6ec71-0ee4-4dc8-a561-32bb36cda544"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Good muffins cost $3.88 in New York. Please buy me two of them. Thanks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "e2aL8Vs3ZiM_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = TweetTokenizer()\n",
        "x = \"Christ is a very reputed college\"\n",
        "y = tk.tokenize(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-lsq-iBZ3DO",
        "outputId": "ef4a65b0-f6f8-4b0a-a16d-55be6218c8aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Christ', 'is', 'a', 'very', 'reputed', 'college']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "rQ8qGAwFaBpZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = (\"Natural language processing (NLP) is a field \" +\n",
        "       \"of computer science, artificial intelligence \" +\n",
        "       \"and computational linguistics concerned with \" +\n",
        "       \"the interactions between computers and human \" +\n",
        "       \"(natural) languages, and, in particular, \" +\n",
        "       \"concerned with programming computers to \" +\n",
        "       \"fruitfully process large natural language \" +\n",
        "       \"corpora. Challenges in natural language \" +\n",
        "       \"processing frequently involve natural \" +\n",
        "       \"language understanding, natural language\" +\n",
        "       \"generation frequently from formal, machine\" +\n",
        "       \"-readable logical forms), connecting language \" +\n",
        "       \"and machine perception, managing human-\" +\n",
        "       \"computer dialog systems, or some combination \" +\n",
        "       \"thereof.\")\n",
        "\n",
        "# create a TextBlob object\n",
        "blob_object = TextBlob(text)\n",
        "\n",
        "# tokenize paragraph into words.\n",
        "print(\" Word Tokenize :\\n\", blob_object.words)\n",
        "\n",
        "# tokenize paragraph into sentences.\n",
        "print(\"\\n Sentence Tokenize :\\n\", blob_object.sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd8ib06-TjbA",
        "outputId": "2ebaa830-c577-4303-8d9e-797e6f33ba13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Word Tokenize :\n",
            " ['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'field', 'of', 'computer', 'science', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'natural', 'languages', 'and', 'in', 'particular', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'languagegeneration', 'frequently', 'from', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'and', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'or', 'some', 'combination', 'thereof']\n",
            "\n",
            " Sentence Tokenize :\n",
            " [Sentence(\"Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora.\"), Sentence(\"Challenges in natural language processing frequently involve natural language understanding, natural languagegeneration frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "ffINFofATwEU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Epsita studies in Christ University. He is 23 years old.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AEjiowbT37U",
        "outputId": "16b70856-0c36-465e-be65-dc1c4eb68f46"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epsita\n",
            "studies\n",
            "in\n",
            "Christ\n",
            "University\n",
            ".\n",
            "He\n",
            "is\n",
            "23\n",
            "years\n",
            "old\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import tokenize"
      ],
      "metadata": {
        "id": "i9sD9VixT_vZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Welcome to Christ University.\"\n",
        "tokens = list(tokenize(text))\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo83ue1mUPHN",
        "outputId": "3ddd7f68-cc3c-409e-8eb3-f9bedac5f26d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Welcome', 'to', 'Christ', 'University']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vkr_PEM9UQaY"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}